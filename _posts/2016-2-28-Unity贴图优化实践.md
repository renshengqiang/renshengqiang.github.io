---
layout: post
author: tnqiang
titile: Unity贴图优化实践
category: Unity
tag: Unity
---
之前一篇文章中说了对贴图进行优化（减小安装包和运行内存），即使用纹理压缩的理论基础。这篇文章我们来说一下纹理压缩的代码实践。

目前主流的 Android 机器支持的仅仅是 ETC1 压缩压缩，所以安卓平台我们使用的是 ETC1 RGB 4bit 的压缩方案。 

iOS 平台如果使用 PVRTC RGBA 4bit 的压缩方案，显示效果不是很理想，因此 iOS 也是将 alpha 拆出来，使用 PVRTC RGB 4bit 的纹理压缩方案。

这样子每个像素其实就是使用了 8bit 的存储空间，因此压缩比是 0.25（8/32），同时 Android/iOS 平台保持统一，比较好处理。
压缩方案主要分为三个部分，后面会有代码来慢慢讲解：

- 纹理图像 alpha 通道拆分
- Shader编写支持 alpha 通道拆分
- 图片组件重写支持 alpha 通道拆分

##纹理 alpha 通道拆分
纹理 alpha 通道拆分其实就是处理每一个像素，将像素的 RGBA 分开成 RGB 和 A 两部分。

在工程中，像素的图片是存储在纹理图片中的，因此拆分后也要存储到纹理图片中。因此拆分的方式有两种：
一种是创建一个新图片，里面填充的是对应原来图片相同位置的 alpha 值；
另一种是将原来的图片加长（或加宽）一倍，多出的部分填充 alpha 值。

一般采取第二种方式，因为同一个图片计算纹理坐标相对来说比较方便。
核心代码如下所示：

{% highlight C# %}

public static Texture2D SplitRGBA2RGBAndA(Texture2D tex, out bool isTransparent)
{
	Texture2D mergeTex; 
	if (tex.width < tex.height) 
		mergeTex = new Texture2D(tex.width * 2 + addPixel, tex.height, TextureFormat.RGB24, false); 
	else 
		mergeTex = new Texture2D(tex.width, tex.height * 2 + addPixel, TextureFormat.RGB24, false); 
	mergeTex.SetPixels(new Color[mergeTex.width * mergeTex.height]); 
	Color[] colors = tex.GetPixels(); 
	mergeTex.SetPixels(0, 0, tex.width, tex.height, colors); 
	float ca = 1 / 3f; 
	isTransparent = false; 
	Color[] alphaColors = new Color[colors.Length]; 
	for (int i = 0; i < colors.Length; i++) 
	{ 
		// alpha通道分成1/3分别存储到冗余图片的RGB通道中可以防止压缩太过
		alphaColors[i].r = alphaColors[i].g = alphaColors[i].b = (colors[i].a * ca); 
		alphaColors[i].a = 1; 
		//标记带透明通道
		if (!isTransparent && colors[i].a < 1) 
			isTransparent = true; 
	} 
	if (!isTransparent) 
	{ 
		//只有不带透明通道，并且面积很大(128 * 128)的时候才不转化
		//这样子可以保证大多数Image使用相同的Material方便batch
		if (tex.width * tex.height > 16384)
			return tex;
	} 
	isTransparent = true; 
	if (tex.width < tex.height) 
		mergeTex.SetPixels(tex.width + addPixel, 0, tex.width, tex.height, alphaColors); 
	else 
		mergeTex.SetPixels(0, tex.height + addPixel, tex.width, tex.height, alphaColors); 
	mergeTex.Apply(); 
	return mergeTex;
}

{% endhighlight %}

##Shader
Shader 部分的改动比较小， 主要改动的地方就是 Vertex Shader 中的传入参数中会多一个 UV 坐标表示 alpha 通道 sprite 的 UV 坐标，然后在 Fragment Shader 中对 RGB 和 A 进行融合，核心代码如下。

{% highlight C# %}

Pass
{
CGPROGRAM
	#pragma vertex vert
	#pragma fragment frag
	#include "UnityCG.cginc"
	sampler2D _MainTex;
	fixed4 _Color;
	struct a2v 
	{
		float4 vertex 	: POSITION;
        float2 texcoord : TEXCOORD0;
        float2 texcoord1: TEXCOORD1;
        float4 color 	: COLOR;
    };
    struct v2f 
    {
         float4 pos : SV_POSITION;
         half2 uv0 : TEXCOORD0;
         half2 uv1 : TEXCOORD1;
         float4 color 	: COLOR;
    };
    v2f vert (a2v v) 
    {
		v2f o;
	    o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
        o.uv0 = v.texcoord;
        o.uv1 = v.texcoord1;
        o.color = v.color * _Color;
        return o;
    }    
    fixed4 frag (v2f i) : SV_Target 
    {
		fixed4 col_i = i.color;
        fixed4 col = tex2D(_MainTex, i.uv0) * col_i;
        fixed4 col2 = tex2D(_MainTex, i.uv1);
        col.a = (col2.r + col2.g + col2.b) * col.a;
        return col;
    }
ENDCG
}

{% endhighlight %}

##uGUI Image 修改
使用 uGUI 的 Image 只会提供一个 UV 坐标到 Shader 中去执行，因此我们需要修改 Image 组件在给 GPU 传递顶点信息的时候计算出 Image 四个顶点 alpha 通道所在的 UV 坐标，给我们的 Shader 传递两个 UV 坐标。

在 Unity 5.x 中我们需要自己实现 
``protected override void OnPopulateMesh(VertexHelper toFill)``。

在 Unity 4.6.x 中我们需要自己实现
``protected override void OnFillVBO (List<UIVertex> vbo)``。

这里可以参考 [uGUI 源码](https://bitbucket.org/Unity-Technologies/ui/src)来进行适当改动，由于这里的改动较多就不贴出代码出来了，大家自己发挥。

##More
1. 如果使用 uGUI，不仅是 Image 组件需要有自己的实现，和 Sprite 有关的组件其实都需要自己来实现，例如 Toggle 等。
2. 另外 NGUI 本人接触不多，但是它也是开源的，因此思路基本上是一致的。
3. 最后还有一个问题是 alpha 通道分离尽量做到编译时候需改图片，替换组件，设置组件先关属性的方式，这样子对其他开发者来说完全无感知，当然这个会给编译时间带去一定的开销。
